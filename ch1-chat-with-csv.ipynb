{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install sqlglot\n",
    "!pip install sqlparse\n",
    "!pip install accelerate\n",
    "!pip install -U pandas sqlalchemy\n",
    "!pip install -U sentence-transformers\n",
    "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV data from Kaggle\n",
    "\n",
    "We are using the [Young People Survey Dataset](https://www.kaggle.com/datasets/miroslavsabo/young-people-survey) from Kaggle. The primary reason for choosing this dataset is because it has a pretty large number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['columns.csv', 'responses.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/kaggle-young-people-survey-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Music</th>\n",
       "      <th>Slow songs or fast songs</th>\n",
       "      <th>Dance</th>\n",
       "      <th>Folk</th>\n",
       "      <th>Country</th>\n",
       "      <th>Classical music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Metal or Hardrock</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Number of siblings</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Left - right handed</th>\n",
       "      <th>Education</th>\n",
       "      <th>Only child</th>\n",
       "      <th>Village - town</th>\n",
       "      <th>House - block of flats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>no</td>\n",
       "      <td>village</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>yes</td>\n",
       "      <td>city</td>\n",
       "      <td>house/bungalow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>no</td>\n",
       "      <td>village</td>\n",
       "      <td>house/bungalow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>house/bungalow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>male</td>\n",
       "      <td>left handed</td>\n",
       "      <td>masters degree</td>\n",
       "      <td>no</td>\n",
       "      <td>village</td>\n",
       "      <td>house/bungalow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>yes</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>no</td>\n",
       "      <td>village</td>\n",
       "      <td>house/bungalow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Music  Slow songs or fast songs  Dance  Folk  Country  Classical music  \\\n",
       "0       5.0                       3.0    2.0   1.0      2.0              2.0   \n",
       "1       4.0                       4.0    2.0   1.0      1.0              1.0   \n",
       "2       5.0                       5.0    2.0   2.0      3.0              4.0   \n",
       "3       5.0                       3.0    2.0   1.0      1.0              1.0   \n",
       "4       5.0                       3.0    4.0   3.0      2.0              4.0   \n",
       "...     ...                       ...    ...   ...      ...              ...   \n",
       "1005    5.0                       2.0    5.0   2.0      2.0              5.0   \n",
       "1006    4.0                       4.0    5.0   1.0      3.0              4.0   \n",
       "1007    4.0                       3.0    1.0   1.0      2.0              2.0   \n",
       "1008    5.0                       3.0    3.0   3.0      1.0              3.0   \n",
       "1009    5.0                       5.0    4.0   3.0      2.0              3.0   \n",
       "\n",
       "      Musical  Pop  Rock  Metal or Hardrock  ...   Age  Height  Weight  \\\n",
       "0         1.0  5.0   5.0                1.0  ...  20.0   163.0    48.0   \n",
       "1         2.0  3.0   5.0                4.0  ...  19.0   163.0    58.0   \n",
       "2         5.0  3.0   5.0                3.0  ...  20.0   176.0    67.0   \n",
       "3         1.0  2.0   2.0                1.0  ...  22.0   172.0    59.0   \n",
       "4         3.0  5.0   3.0                1.0  ...  20.0   170.0    59.0   \n",
       "...       ...  ...   ...                ...  ...   ...     ...     ...   \n",
       "1005      4.0  4.0   4.0                3.0  ...  20.0   164.0    57.0   \n",
       "1006      1.0  4.0   1.0                1.0  ...  27.0   183.0    80.0   \n",
       "1007      2.0  3.0   4.0                1.0  ...  18.0   173.0    75.0   \n",
       "1008      1.0  3.0   4.0                1.0  ...  25.0   173.0    58.0   \n",
       "1009      3.0  4.0   1.0                1.0  ...  21.0   185.0    72.0   \n",
       "\n",
       "      Number of siblings  Gender  Left - right handed  \\\n",
       "0                    1.0  female         right handed   \n",
       "1                    2.0  female         right handed   \n",
       "2                    2.0  female         right handed   \n",
       "3                    1.0  female         right handed   \n",
       "4                    1.0  female         right handed   \n",
       "...                  ...     ...                  ...   \n",
       "1005                 1.0  female         right handed   \n",
       "1006                 5.0    male          left handed   \n",
       "1007                 0.0  female         right handed   \n",
       "1008                 1.0  female         right handed   \n",
       "1009                 1.0    male         right handed   \n",
       "\n",
       "                    Education  Only child  Village - town  \\\n",
       "0     college/bachelor degree          no         village   \n",
       "1     college/bachelor degree          no            city   \n",
       "2            secondary school          no            city   \n",
       "3     college/bachelor degree         yes            city   \n",
       "4            secondary school          no         village   \n",
       "...                       ...         ...             ...   \n",
       "1005         secondary school          no            city   \n",
       "1006           masters degree          no         village   \n",
       "1007         secondary school         yes            city   \n",
       "1008  college/bachelor degree          no            city   \n",
       "1009         secondary school          no         village   \n",
       "\n",
       "      House - block of flats  \n",
       "0             block of flats  \n",
       "1             block of flats  \n",
       "2             block of flats  \n",
       "3             house/bungalow  \n",
       "4             house/bungalow  \n",
       "...                      ...  \n",
       "1005          house/bungalow  \n",
       "1006          house/bungalow  \n",
       "1007          block of flats  \n",
       "1008          block of flats  \n",
       "1009          house/bungalow  \n",
       "\n",
       "[1010 rows x 150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/kaggle-young-people-survey-dataset/responses.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'young-people-survey'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into SQLite DB\n",
    "\n",
    "For a demonstration of real-world usecases, we will load our CSV data into a database. Once done, we will extract the DDL or the Database Definition Language, i.e. the commands which actually define our table, or more accurately, our table schema.\n",
    "\n",
    "We will use `sqlite` for this usecase but you can use your DB of choice. You will need to of course install any relevant libraries to communicate with your DB using python.\n",
    "For simplicity's sake, we use built-in functions of Pandas to load and read data from the database. Of course, you can use your DB connector as well to peform these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(f\"sqlite:///mysqlitedb.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df.to_sql(table_name, engine, index=False)\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sqlite` databases contain a table known as `sqlite_master` which contains the details of all tables hosted by the database. This table contains the \"derived\" DDL for each table. If you are using any other database, the process for getting the DDL for your table might be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"young-people-survey\" (\n",
      "\t\"Music\" FLOAT, \n",
      "\t\"Slow songs or fast songs\" FLOAT, \n",
      "\t\"Dance\" FLOAT, \n",
      "\t\"Folk\" FLOAT, \n",
      "\t\"Country\" FLOAT, \n",
      "\t\"Classical music\" FLOAT, \n",
      "\t\"Musical\" FLOAT, \n",
      "\t\"Pop\" FLOAT, \n",
      "\t\"Rock\" FLOAT, \n",
      "\t\"Metal or Hardrock\" FLOAT, \n",
      "\t\"Punk\" FLOAT, \n",
      "\t\"Hiphop, Rap\" FLOAT, \n",
      "\t\"Reggae, Ska\" FLOAT, \n",
      "\t\"Swing, Jazz\" FLOAT, \n",
      "\t\"Rock n roll\" FLOAT, \n",
      "\t\"Alternative\" FLOAT, \n",
      "\t\"Latino\" FLOAT, \n",
      "\t\"Techno, Trance\" FLOAT, \n",
      "\t\"Opera\" FLOAT, \n",
      "\t\"Movies\" FLOAT, \n",
      "\t\"Horror\" FLOAT, \n",
      "\t\"Thriller\" FLOAT, \n",
      "\t\"Comedy\" FLOAT, \n",
      "\t\"Romantic\" FLOAT, \n",
      "\t\"Sci-fi\" FLOAT, \n",
      "\t\"War\" FLOAT, \n",
      "\t\"Fantasy/Fairy tales\" FLOAT, \n",
      "\t\"Animated\" FLOAT, \n",
      "\t\"Documentary\" FLOAT, \n",
      "\t\"Western\" FLOAT, \n",
      "\t\"Action\" FLOAT, \n",
      "\t\"History\" FLOAT, \n",
      "\t\"Psychology\" FLOAT, \n",
      "\t\"Politics\" FLOAT, \n",
      "\t\"Mathematics\" FLOAT, \n",
      "\t\"Physics\" FLOAT, \n",
      "\t\"Internet\" FLOAT, \n",
      "\t\"PC\" FLOAT, \n",
      "\t\"Economy Management\" FLOAT, \n",
      "\t\"Biology\" FLOAT, \n",
      "\t\"Chemistry\" FLOAT, \n",
      "\t\"Reading\" FLOAT, \n",
      "\t\"Geography\" FLOAT, \n",
      "\t\"Foreign languages\" FLOAT, \n",
      "\t\"Medicine\" FLOAT, \n",
      "\t\"Law\" FLOAT, \n",
      "\t\"Cars\" FLOAT, \n",
      "\t\"Art exhibitions\" FLOAT, \n",
      "\t\"Religion\" FLOAT, \n",
      "\t\"Countryside, outdoors\" FLOAT, \n",
      "\t\"Dancing\" FLOAT, \n",
      "\t\"Musical instruments\" FLOAT, \n",
      "\t\"Writing\" FLOAT, \n",
      "\t\"Passive sport\" FLOAT, \n",
      "\t\"Active sport\" FLOAT, \n",
      "\t\"Gardening\" FLOAT, \n",
      "\t\"Celebrities\" FLOAT, \n",
      "\t\"Shopping\" FLOAT, \n",
      "\t\"Science and technology\" FLOAT, \n",
      "\t\"Theatre\" FLOAT, \n",
      "\t\"Fun with friends\" FLOAT, \n",
      "\t\"Adrenaline sports\" FLOAT, \n",
      "\t\"Pets\" FLOAT, \n",
      "\t\"Flying\" FLOAT, \n",
      "\t\"Storm\" FLOAT, \n",
      "\t\"Darkness\" FLOAT, \n",
      "\t\"Heights\" FLOAT, \n",
      "\t\"Spiders\" FLOAT, \n",
      "\t\"Snakes\" BIGINT, \n",
      "\t\"Rats\" FLOAT, \n",
      "\t\"Ageing\" FLOAT, \n",
      "\t\"Dangerous dogs\" FLOAT, \n",
      "\t\"Fear of public speaking\" FLOAT, \n",
      "\t\"Smoking\" TEXT, \n",
      "\t\"Alcohol\" TEXT, \n",
      "\t\"Healthy eating\" FLOAT, \n",
      "\t\"Daily events\" FLOAT, \n",
      "\t\"Prioritising workload\" FLOAT, \n",
      "\t\"Writing notes\" FLOAT, \n",
      "\t\"Workaholism\" FLOAT, \n",
      "\t\"Thinking ahead\" FLOAT, \n",
      "\t\"Final judgement\" FLOAT, \n",
      "\t\"Reliability\" FLOAT, \n",
      "\t\"Keeping promises\" FLOAT, \n",
      "\t\"Loss of interest\" FLOAT, \n",
      "\t\"Friends versus money\" FLOAT, \n",
      "\t\"Funniness\" FLOAT, \n",
      "\t\"Fake\" FLOAT, \n",
      "\t\"Criminal damage\" FLOAT, \n",
      "\t\"Decision making\" FLOAT, \n",
      "\t\"Elections\" FLOAT, \n",
      "\t\"Self-criticism\" FLOAT, \n",
      "\t\"Judgment calls\" FLOAT, \n",
      "\t\"Hypochondria\" FLOAT, \n",
      "\t\"Empathy\" FLOAT, \n",
      "\t\"Eating to survive\" BIGINT, \n",
      "\t\"Giving\" FLOAT, \n",
      "\t\"Compassion to animals\" FLOAT, \n",
      "\t\"Borrowed stuff\" FLOAT, \n",
      "\t\"Loneliness\" FLOAT, \n",
      "\t\"Cheating in school\" FLOAT, \n",
      "\t\"Health\" FLOAT, \n",
      "\t\"Changing the past\" FLOAT, \n",
      "\t\"God\" FLOAT, \n",
      "\t\"Dreams\" BIGINT, \n",
      "\t\"Charity\" FLOAT, \n",
      "\t\"Number of friends\" BIGINT, \n",
      "\t\"Punctuality\" TEXT, \n",
      "\t\"Lying\" TEXT, \n",
      "\t\"Waiting\" FLOAT, \n",
      "\t\"New environment\" FLOAT, \n",
      "\t\"Mood swings\" FLOAT, \n",
      "\t\"Appearence and gestures\" FLOAT, \n",
      "\t\"Socializing\" FLOAT, \n",
      "\t\"Achievements\" FLOAT, \n",
      "\t\"Responding to a serious letter\" FLOAT, \n",
      "\t\"Children\" FLOAT, \n",
      "\t\"Assertiveness\" FLOAT, \n",
      "\t\"Getting angry\" FLOAT, \n",
      "\t\"Knowing the right people\" FLOAT, \n",
      "\t\"Public speaking\" FLOAT, \n",
      "\t\"Unpopularity\" FLOAT, \n",
      "\t\"Life struggles\" FLOAT, \n",
      "\t\"Happiness in life\" FLOAT, \n",
      "\t\"Energy levels\" FLOAT, \n",
      "\t\"Small - big dogs\" FLOAT, \n",
      "\t\"Personality\" FLOAT, \n",
      "\t\"Finding lost valuables\" FLOAT, \n",
      "\t\"Getting up\" FLOAT, \n",
      "\t\"Interests or hobbies\" FLOAT, \n",
      "\t\"Parents' advice\" FLOAT, \n",
      "\t\"Questionnaires or polls\" FLOAT, \n",
      "\t\"Internet usage\" TEXT, \n",
      "\t\"Finances\" FLOAT, \n",
      "\t\"Shopping centres\" FLOAT, \n",
      "\t\"Branded clothing\" FLOAT, \n",
      "\t\"Entertainment spending\" FLOAT, \n",
      "\t\"Spending on looks\" FLOAT, \n",
      "\t\"Spending on gadgets\" BIGINT, \n",
      "\t\"Spending on healthy eating\" FLOAT, \n",
      "\t\"Age\" FLOAT, \n",
      "\t\"Height\" FLOAT, \n",
      "\t\"Weight\" FLOAT, \n",
      "\t\"Number of siblings\" FLOAT, \n",
      "\t\"Gender\" TEXT, \n",
      "\t\"Left - right handed\" TEXT, \n",
      "\t\"Education\" TEXT, \n",
      "\t\"Only child\" TEXT, \n",
      "\t\"Village - town\" TEXT, \n",
      "\t\"House - block of flats\" TEXT\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    sqlite_master = pd.read_sql_query(\"SELECT * FROM sqlite_master\", conn)\n",
    "sqlite_master['sql_fmt'] = sqlite_master['sql'].apply(lambda z: [x.strip().strip(',').rsplit(' ', maxsplit=1) for x in z.split('\\n')[1:-1]])\n",
    "\n",
    "table_desc_dict = {}\n",
    "for _, row in sqlite_master.iterrows():\n",
    "    table_desc_dict[row['name']] = row['sql']\n",
    "\n",
    "schema = table_desc_dict[table_name]\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Music\"</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Slow songs or fast songs\"</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Dance\"</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Folk\"</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Country\"</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>\"Left - right handed\"</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>\"Education\"</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>\"Only child\"</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>\"Village - town\"</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>\"House - block of flats\"</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name   type  comment\n",
       "0                       \"Music\"  FLOAT      NaN\n",
       "1    \"Slow songs or fast songs\"  FLOAT      NaN\n",
       "2                       \"Dance\"  FLOAT      NaN\n",
       "3                        \"Folk\"  FLOAT      NaN\n",
       "4                     \"Country\"  FLOAT      NaN\n",
       "..                          ...    ...      ...\n",
       "145       \"Left - right handed\"   TEXT      NaN\n",
       "146                 \"Education\"   TEXT      NaN\n",
       "147                \"Only child\"   TEXT      NaN\n",
       "148            \"Village - town\"   TEXT      NaN\n",
       "149    \"House - block of flats\"   TEXT      NaN\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_desc_df = {}\n",
    "for _, row in sqlite_master.iterrows():\n",
    "    table_desc_df[row['name']] = pd.DataFrame(columns=['name', 'type'], data=row['sql_fmt'])\n",
    "    table_desc_df[row['name']]['comment'] = np.nan\n",
    "\n",
    "table_desc_df['young-people-survey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prompt LLM to generate SQL\n",
    "You can use your LLM of choice to generate SQL commands, but models specifically fine-tuned to generate high-quality SQL are obviously prefered. We will use the model [`llama-3-sqlcoder-8b` by Defog](https://huggingface.co/defog/llama-3-sqlcoder-8b), which was derived by finetunig the `llama-3` model released by Meta.\n",
    "\n",
    "While we will be prompting the model as described by the model's creators, feel free to experiment with other models and other prompt templates. Other popular LLMs for code generation are [`Deepseek-Coder-V2` by DeepSeek (深度求索)](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct) and [`CodeQwen1.5-7B-Chat` by Qwen](https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat)\n",
    "\n",
    "### Benchmarks\n",
    "<details>\n",
    "<summary> HumanEval </summary>\n",
    "\n",
    "[HumanEval](https://paperswithcode.com/dataset/humaneval) problem solving dataset is introduced in the paper \"Evaluating Large Language Models Trained on Code\". It used to measure functional correctness for synthesizing programs from docstrings. It consists of 164 original programming problems, assessing language comprehension, algorithms, and simple mathematics, with some comparable to simple software interview questions.\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> EvalPlus </summary>\n",
    "\n",
    "[EvalPlus](https://github.com/evalplus/evalplus) is a rigorous evaluation framework for LLM4Code, with:  \n",
    "✨ HumanEval+: 80x more tests than the original HumanEval!  \n",
    "✨ MBPP+: 35x more tests than the original MBPP!  \n",
    "[...]  \n",
    "Why EvalPlus? What does using EvalPlus datasets bring to you?  \n",
    "✨ Reliable ranking: See our leaderboard for the latest LLM ranking before and after rigorous evaluation.  \n",
    "✨ Code robustness: Look at the score differences! esp. before (e.g., HumanEval) and after (e.g., HumanEval+) using EvalPlus! The drop/gap indicates if the LLM can generate more robust code: less drop means more robustness and a larger drop means the code tends to be more fragile.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> InfiCoder-eval </summary>\n",
    "\n",
    "[InfiCoder-eval](https://infi-coder.github.io/inficoder-eval) is a large-scale free-form question-answering (QA) benchmark for code. InfiCoder-Eval comprises 270 carefully picked high-quality StackOverflow questions, covering 18 programming languages. [...] As confirmed with human experiments, InfiCoder-Eval evaluation aligns with humans better than model-based evaluation and runs much faster at the same time. [...] Existing benchmarks weigh heavily on code generation, unit-test-based evaluation, and a limited set of programming languages. InfiCoder-Eval processes a much higher diversity to reflect real-world code LLMs’ usage scenarios and is far from saturation.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> LMSYS Chatbot Arena Leaderboard </summary>\n",
    "\n",
    "[LMSYS Chatbot Arena](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) is a crowdsourced open platform for LLM evals. We've collected over 200,000 human preference votes to rank LLMs with the Elo ranking system.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> Big Code Models Leaderboard </summary>\n",
    "\n",
    "[Big Code Models Leaderboard (open source models only)](https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard) compares performance of base multilingual code generation models on HumanEval benchmark and MultiPL-E. We also measure throughput and provide information about the models. We only compare open pre-trained multilingual code models, that people can start from as base models for their trainings. Win Rate represents how often a model outperforms other models in each language, averaged across all languages. The scores of instruction-tuned models might be significantly higher on humaneval-python than other languages. [...] HumanEval-Python reports the pass@1 on HumanEval; the rest is from MultiPL-E benchmark. For all languages, we use the original benchamrk prompts for all models except HumanEval-Python, where we separate base from instruction models.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"defog/llama-3-sqlcoder-8b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# else, load in 8 bits – this is a bit slower\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    # torch_dtype=torch.float16,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "\n",
    "def generate_query(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=400,\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "    )\n",
    "    outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    # empty cache so that you do generate more results w/o memory crashing\n",
    "    # particularly important on Colab – memory management is much more straightforward\n",
    "    # when running on an inference service\n",
    "    return sqlparse.format(outputs[0].split(\"[SQL]\")[-1], reindent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuned LLMs are very sensitive to the prompt. Make sure you are using the prompt format specified by the creators of the model. You can usually get this information in the HuggingFace model card or in Github repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task\n",
      "Generate a SQL query to answer [QUESTION]Which are the rows which have 1 for at least one music related column?[/QUESTION] \n",
      "\n",
      "### Instructions\n",
      "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
      "\n",
      "## Database Schema \n",
      "This query will run on a database whose schema is represented in this string: CREATE TABLE \"young-people-survey\" (\n",
      "\t\"Music\" FLOAT, \n",
      "\t\"Slow songs or fast songs\" FLOAT, \n",
      "\t\"Dance\" FLOAT, \n",
      "\t\"Folk\" FLOAT, \n",
      "\t\"Country\" FLOAT, \n",
      "\t\"Classical music\" FLOAT, \n",
      "\t\"Musical\" FLOAT, \n",
      "\t\"Pop\" FLOAT, \n",
      "\t\"Rock\" FLOAT, \n",
      "\t\"Metal or Hardrock\" FLOAT, \n",
      "\t\"Punk\" FLOAT, \n",
      "\t\"Hiphop, Rap\" FLOAT, \n",
      "\t\"Reggae, Ska\" FLOAT, \n",
      "\t\"Swing, Jazz\" FLOAT, \n",
      "\t\"Rock n roll\" FLOAT, \n",
      "\t\"Alternative\" FLOAT, \n",
      "\t\"Latino\" FLOAT, \n",
      "\t\"Techno, Trance\" FLOAT, \n",
      "\t\"Opera\" FLOAT, \n",
      "\t\"Movies\" FLOAT, \n",
      "\t\"Horror\" FLOAT, \n",
      "\t\"Thriller\" FLOAT, \n",
      "\t\"Comedy\" FLOAT, \n",
      "\t\"Romantic\" FLOAT, \n",
      "\t\"Sci-fi\" FLOAT, \n",
      "\t\"War\" FLOAT, \n",
      "\t\"Fantasy/Fairy tales\" FLOAT, \n",
      "\t\"Animated\" FLOAT, \n",
      "\t\"Documentary\" FLOAT, \n",
      "\t\"Western\" FLOAT, \n",
      "\t\"Action\" FLOAT, \n",
      "\t\"History\" FLOAT, \n",
      "\t\"Psychology\" FLOAT, \n",
      "\t\"Politics\" FLOAT, \n",
      "\t\"Mathematics\" FLOAT, \n",
      "\t\"Physics\" FLOAT, \n",
      "\t\"Internet\" FLOAT, \n",
      "\t\"PC\" FLOAT, \n",
      "\t\"Economy Management\" FLOAT, \n",
      "\t\"Biology\" FLOAT, \n",
      "\t\"Chemistry\" FLOAT, \n",
      "\t\"Reading\" FLOAT, \n",
      "\t\"Geography\" FLOAT, \n",
      "\t\"Foreign languages\" FLOAT, \n",
      "\t\"Medicine\" FLOAT, \n",
      "\t\"Law\" FLOAT, \n",
      "\t\"Cars\" FLOAT, \n",
      "\t\"Art exhibitions\" FLOAT, \n",
      "\t\"Religion\" FLOAT, \n",
      "\t\"Countryside, outdoors\" FLOAT, \n",
      "\t\"Dancing\" FLOAT, \n",
      "\t\"Musical instruments\" FLOAT, \n",
      "\t\"Writing\" FLOAT, \n",
      "\t\"Passive sport\" FLOAT, \n",
      "\t\"Active sport\" FLOAT, \n",
      "\t\"Gardening\" FLOAT, \n",
      "\t\"Celebrities\" FLOAT, \n",
      "\t\"Shopping\" FLOAT, \n",
      "\t\"Science and technology\" FLOAT, \n",
      "\t\"Theatre\" FLOAT, \n",
      "\t\"Fun with friends\" FLOAT, \n",
      "\t\"Adrenaline sports\" FLOAT, \n",
      "\t\"Pets\" FLOAT, \n",
      "\t\"Flying\" FLOAT, \n",
      "\t\"Storm\" FLOAT, \n",
      "\t\"Darkness\" FLOAT, \n",
      "\t\"Heights\" FLOAT, \n",
      "\t\"Spiders\" FLOAT, \n",
      "\t\"Snakes\" BIGINT, \n",
      "\t\"Rats\" FLOAT, \n",
      "\t\"Ageing\" FLOAT, \n",
      "\t\"Dangerous dogs\" FLOAT, \n",
      "\t\"Fear of public speaking\" FLOAT, \n",
      "\t\"Smoking\" TEXT, \n",
      "\t\"Alcohol\" TEXT, \n",
      "\t\"Healthy eating\" FLOAT, \n",
      "\t\"Daily events\" FLOAT, \n",
      "\t\"Prioritising workload\" FLOAT, \n",
      "\t\"Writing notes\" FLOAT, \n",
      "\t\"Workaholism\" FLOAT, \n",
      "\t\"Thinking ahead\" FLOAT, \n",
      "\t\"Final judgement\" FLOAT, \n",
      "\t\"Reliability\" FLOAT, \n",
      "\t\"Keeping promises\" FLOAT, \n",
      "\t\"Loss of interest\" FLOAT, \n",
      "\t\"Friends versus money\" FLOAT, \n",
      "\t\"Funniness\" FLOAT, \n",
      "\t\"Fake\" FLOAT, \n",
      "\t\"Criminal damage\" FLOAT, \n",
      "\t\"Decision making\" FLOAT, \n",
      "\t\"Elections\" FLOAT, \n",
      "\t\"Self-criticism\" FLOAT, \n",
      "\t\"Judgment calls\" FLOAT, \n",
      "\t\"Hypochondria\" FLOAT, \n",
      "\t\"Empathy\" FLOAT, \n",
      "\t\"Eating to survive\" BIGINT, \n",
      "\t\"Giving\" FLOAT, \n",
      "\t\"Compassion to animals\" FLOAT, \n",
      "\t\"Borrowed stuff\" FLOAT, \n",
      "\t\"Loneliness\" FLOAT, \n",
      "\t\"Cheating in school\" FLOAT, \n",
      "\t\"Health\" FLOAT, \n",
      "\t\"Changing the past\" FLOAT, \n",
      "\t\"God\" FLOAT, \n",
      "\t\"Dreams\" BIGINT, \n",
      "\t\"Charity\" FLOAT, \n",
      "\t\"Number of friends\" BIGINT, \n",
      "\t\"Punctuality\" TEXT, \n",
      "\t\"Lying\" TEXT, \n",
      "\t\"Waiting\" FLOAT, \n",
      "\t\"New environment\" FLOAT, \n",
      "\t\"Mood swings\" FLOAT, \n",
      "\t\"Appearence and gestures\" FLOAT, \n",
      "\t\"Socializing\" FLOAT, \n",
      "\t\"Achievements\" FLOAT, \n",
      "\t\"Responding to a serious letter\" FLOAT, \n",
      "\t\"Children\" FLOAT, \n",
      "\t\"Assertiveness\" FLOAT, \n",
      "\t\"Getting angry\" FLOAT, \n",
      "\t\"Knowing the right people\" FLOAT, \n",
      "\t\"Public speaking\" FLOAT, \n",
      "\t\"Unpopularity\" FLOAT, \n",
      "\t\"Life struggles\" FLOAT, \n",
      "\t\"Happiness in life\" FLOAT, \n",
      "\t\"Energy levels\" FLOAT, \n",
      "\t\"Small - big dogs\" FLOAT, \n",
      "\t\"Personality\" FLOAT, \n",
      "\t\"Finding lost valuables\" FLOAT, \n",
      "\t\"Getting up\" FLOAT, \n",
      "\t\"Interests or hobbies\" FLOAT, \n",
      "\t\"Parents' advice\" FLOAT, \n",
      "\t\"Questionnaires or polls\" FLOAT, \n",
      "\t\"Internet usage\" TEXT, \n",
      "\t\"Finances\" FLOAT, \n",
      "\t\"Shopping centres\" FLOAT, \n",
      "\t\"Branded clothing\" FLOAT, \n",
      "\t\"Entertainment spending\" FLOAT, \n",
      "\t\"Spending on looks\" FLOAT, \n",
      "\t\"Spending on gadgets\" BIGINT, \n",
      "\t\"Spending on healthy eating\" FLOAT, \n",
      "\t\"Age\" FLOAT, \n",
      "\t\"Height\" FLOAT, \n",
      "\t\"Weight\" FLOAT, \n",
      "\t\"Number of siblings\" FLOAT, \n",
      "\t\"Gender\" TEXT, \n",
      "\t\"Left - right handed\" TEXT, \n",
      "\t\"Education\" TEXT, \n",
      "\t\"Only child\" TEXT, \n",
      "\t\"Village - town\" TEXT, \n",
      "\t\"House - block of flats\" TEXT\n",
      ") \n",
      "\n",
      "### Answer \n",
      "Given the database schema, here is the SQL query that answers [QUESTION]Which are the rows which have 1 for at least one music related column?[/QUESTION] [SQL]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = 'Which are the rows which have 1 for at least one music related column?'\n",
    "\n",
    "prompt_template = \"\"\"### Task\n",
    "Generate a SQL query to answer [QUESTION]{question}[/QUESTION] \n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "\n",
    "## Database Schema \n",
    "This query will run on a database whose schema is represented in this string: {db_schema} \n",
    "\n",
    "### Answer \n",
    "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION] [SQL]\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, db_schema=schema)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql = generate_query(prompt)\n",
    "print(f'SQL generated by the model: {generated_sql}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we execute the generated SQL query on our DB and verify its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"sqlite:///mysqlitedb.db\")\n",
    "\n",
    "with engine.connect() as conn, conn.begin():\n",
    "    query_result = pd.read_sql_query(generated_sql, conn)\n",
    "\n",
    "query_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
